# Загварын гүйцэтгэлийн нарийвчилсан дүн шинжилгээ

## Ерөнхий тойм

Энэхүү логистик регрессийн загвар нь хүмүүсийн жилийн орлогыг ангилах зорилготой бөгөөд хоёр класс (`≤50K` болон `>50K`) хоорондоо ялгах чадвартай байна. Загвар нь gradient descent алгоритм ашиглан сургагдсан бөгөөд L2 regularization, class weighting, learning rate decay зэрэг техникүүдийг хослуулсан.

## Үндсэн гүйцэтгэлийн үзүүлэлтүүд

### Нийт үзүүлэлтүүд

- **Accuracy**: ~0.80 (80%)
- **Precision**: ~0.66
- **Recall**: ~0.59
- **F1 Score**: ~0.62
- **Threshold**: 0.5

### Интерпретаци

**Accuracy (80%)**: Загвар нийт таамаглалуудынхаа 80%-ийг зөв гаргаж байна. Энэ нь сайн үр дүн мэт санагдаж болох ч өгөгдлийн тэнцвэргүй байдал (76% нь `≤50K` класс) -ыг харгалзан үзэх хэрэгтэй. Naive baseline загвар (үргэлж `≤50K` гэж таамагла) нь 76% accuracy өгөх байсан тул бидний загвар үүнээс зөвхөн 4%-аар илүү байна.

**Precision (66%)**: Загварын `>50K` гэж таамагласан хүмүүсийн 66% нь үнэхээр `>50K` орлоготой байна. Өөрөөр хэлбэл, 3 хүнээс 1 нь буруу эерэг (false positive) таамаглал юм. Энэ нь зарим `≤50K` орлоготой хүмүүсийг загвар буруугаар `>50K` гэж ангилж байна гэсэн үг.

**Recall (59%)**: Үнэхээр `>50K` орлоготой хүмүүсийн зөвхөн 59%-ийг загвар илрүүлж чадаж байна. Энэ нь хамгийн сул тал юм - бараг хагас нь (41%) цөөнх классын гишүүдийг алдаж байна (false negative).

**F1 Score (62%)**: Precision болон Recall-ийн гармоник дундаж. Энэ нь тэнцвэргүй өгөгдөлд илүү үнэнч үзүүлэлт бөгөөд загварын нийт чадварыг харуулж байна.

## Класс бүрийн гүйцэтгэл

### Класс 0 (≤50K - Олонх класс)

- **Precision**: 0.89
- **Recall**: 0.91
- **F1**: 0.90

Загвар олонх классыг маш сайн ангилж байна. Энэ нь гайхалтай биш - өгөгдлийн 76% нь энэ класс тул загвар үүн дээр илүү "дадсан" байна.

### Класс 1 (>50K - Цөөнх класс)

- **Precision**: 0.66
- **Recall**: 0.59
- **F1**: 0.62

Цөөнх классын гүйцэтгэл нь хамаагүй доогуур байна. Энэ нь:

1. **Өгөгдлийн тэнцвэргүй байдал**: Зөвхөн 24% нь `>50K` тул загвар хангалттай жишээ харж сурч чадаагүй.
2. **Онцлогуудын давхцал**: Зарим `≤50K` болон `>50K` хүмүүс ижил төстэй онцлогуудтай байж болно (жишээ нь, залуу, өндөр боловсролтой гэхдээ анхны ажлын байранд байгаа хүн).
3. **Шийдвэрийн хязгаарын сонголт**: 0.5 threshold нь нейтраль боловч цөөнх классын recall-ийг нэмэгдүүлэхийн тулд доошлуулж болох байсан.

## Confusion Matrix Шинжилгээ

Confusion matrix-аас үзэхэд:

- **True Negatives (TN)**: Маш өндөр - олонх классыг зөв таамагласан
- **True Positives (TP)**: Дунд зэрэг - цөөнх классын зарим хэсгийг зөв таамагласан
- **False Positives (FP)**: Дунд зэрэг - зарим `≤50K` хүмүүсийг `>50K` гэж таамагласан
- **False Negatives (FN)**: Харьцангуй өндөр - олон `>50K` хүмүүсийг `≤50K` гэж таамагласан

False Negatives нь өндөр байгаа нь recall бага байгаатай тохирч байна.

## Сургалтын процесс

### Алдааны бууралт

Notebook-ийн график нь:

- Алдаа нь тогтвортой, мөдөн буурч байна
- Гэнэтийн үсрэлт эсвэл тогтворгүй байдал байхгүй
- Энэ нь градиент бууруулалт зөв ажиллаж, learning rate decay оновчтой байгааг харуулж байна

### Learning Rate Decay

Learning rate нь цаг хугацааны явцад буурч байгаа нь:

- Эхэндээ хурдан суралцах
- Минимумын ойролцоо нарийвчлалтай алхах
- Овершутинг болон тогтворгүй байдлаас сэргийлэх

## Онцлогуудын ач холбогдол

### Хамгийн чухал онцлогууд

**Эерэг (>50K рүү түлхэх)**:

1. `educational-num` (+0.89): Хамгийн хүчтэй хүчин зүйл
2. `capital-gain` (+0.76): Хөрөнгө оруулалтын орлого
3. `occupation_Exec-managerial` (+0.52): Удирдлагын албан тушаал
4. `marital-status_Married-civ-spouse` (+0.46): Гэрлэсэн байдал

**Сөрөг (≤50K рүү түлхэх)**:

1. `occupation_Other-service` (-0.67): Үйлчилгээний ажил
2. `marital-status_Never-married` (-0.48): Ганц бие
3. `capital-loss` (-0.41): Хөрөнгийн алдагдал

Эдгээр жингүүд нь бодит ертөнцийн ойлголттой нийцэж байна.

## Магадлалын тархалт

Хоёр классын магадлалын тархалт давхцаж байна:

- `≤50K`: Дундаж магадлал ~0.18, ихэнх нь 0-0.3
- `>50K`: Дундаж магадлал ~0.57, илүү өргөн тархалттай (0.2-0.9)

Энэ давхцал нь яагаад загвар төгс биш болохыг тайлбарлаж байна. Зарим `>50K` хүмүүс бага магадлалтай, зарим `≤50K` хүмүүс өндөр магадлалтай гарч байна.

## ROC-AUC

ROC AUC = 0.891 нь:

- Санамсаргүй таамаглалаас (0.5) хамаагүй дээгүүр
- Төгс ангилалаас (1.0) хол
- Практикт "сайн" үзүүлэлт
- Загвар нь классуудыг ялгах чадвартай гэдгийг харуулж байна

## Precision-Recall Trade-off

Threshold optimization graphic нь:

- Recall-ийг өсгөвөл Precision буурна
- Precision-ийг өсгөвөл Recall буурна
- Optimal threshold нь F1-ийг максимизл хийх газар (~0.5 орчим)

Threshold-ийг доошлуулбал илүү олон `>50K` хүмүүсийг олж болох (recall өснө) гэхдээ илүү олон false positives авах болно (precision буурна).

## Сул тал

1. **Бага Recall**: Цөөнх классын 41%-ийг алдаж байна
2. **Тэнцвэргүй байдал**: Классын тэнцвэргүй байдал нь гүйцэтгэлд томоохон нөлөө үзүүлж байна
3. **Threshold оновчлол**: 0.5 нь нейтраль боловч цөөнх классын recall-ийг нэмэгдүүлэхийн тулд тохируулж болох
4. **Хязгаарлагдмал онцлогууд**: Зөвхөн 9 онцлог ашигласан нь илүү их мэдээлэл алдаж байж болзошгүй

## Давуу тал

1. **Тогтвортой сургалт**: Алдаа нь мөдөн буурч, convergence хүрсэн
2. **Тайлбарлах боломжтой**: Онцлогуудын жингүүд нь бодит утга санаатай
3. **Regularization**: Overfitting-ээс амжилттай сэргийлсэн
4. **Class weighting**: Тэнцвэргүй байдлыг зохицуулах оролдлого хийсэн

## Сайжруулах санал

1. **Threshold тохируулах**: 0.4 эсвэл 0.45 руу доошлуулж recall өсгөх
2. **Илүү олон онцлог**: Цуцлагдсан онцлогуудыг (workclass, relationship, г.м.) буцааж оруулах
3. **Feature engineering**: Онцлогуудыг харилцан үйлчлүүлэх (жишээ нь, age × education)
4. **Илүү төвөгтэй загварууд**: Random Forest, Gradient Boosting оролдох
5. **SMOTE эсвэл undersampling**: Тэнцвэргүй байдлыг илүү сайн зохицуулах
6. **Ensemble methods**: Олон загварыг хослуулах

## Дүгнэлт

Загвар нь ерөнхийдөө сайн гүйцэтгэлтэй (80% accuracy, 0.891 AUC) боловч цөөнх классыг таних нь сул тал юм (59% recall). Энэ нь тэнцвэргүй өгөгдлийн ердийн асуудал бөгөөд threshold optimization, илүү олон онцлог, болон илүү төвөгтэй загваруудаар сайжруулж болно.

Практикт:
- Хэрэв бид өндөр орлоготой хүмүүсийг алдахыг эвлэрхийлж чадахгүй бол recall-д анхаарах (threshold доошлуулах)
- Хэрэв бид false positives-ийг багасгах хэрэгтэй бол precision-д анхаарах (threshold өсгөх)
- Одоогийн F1 = 0.62 нь тэнцвэртэй сонголт юм

Оюутны төслийн хувьд энэ нь хүлээн зөвшөөрөгдөх үр дүн бөгөөд логистик регрессийн онол болон практикийн хэрэглээг сайн харуулж байна.
