% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  mongolian,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{CMU Serif}
  \setsansfont[]{CMU Sans Serif}
  \setmonofont[]{CMU Typewriter Text}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother



\ifLuaTeX
\usepackage[bidi=basic,provide=*]{babel}
\else
\usepackage[bidi=default,provide=*]{babel}
\fi
\ifPDFTeX
\else
\babelfont{rm}[]{CMU Serif}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}


\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


% Mongolian + CMU font setup with fallback
\usepackage{polyglossia}
\setmainlanguage{mongolian}
\setotherlanguage{english}
\IfFontExistsTF{CMU Serif}{%
  \setmainfont{CMU Serif}
  \setsansfont{CMU Sans Serif}
  \setmonofont{CMU Typewriter Text}
  \newfontfamily\mongolianfont{CMU Serif}
}{%
  \setmainfont{TeX Gyre Termes} % fallback with Cyrillic
  \setsansfont{TeX Gyre Heros}
  \setmonofont{TeX Gyre Cursor}
  \newfontfamily\mongolianfont{TeX Gyre Termes}
}
\usepackage{graphicx}
\usepackage{geometry}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdflang={mn},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\author{}
\date{}
\begin{document}


\begin{titlepage}
\centering
\vspace*{2cm}

\includegraphics[width=0.4\textwidth]{images/numlogo.png}

\vspace{1.5cm}

{\Huge\bfseries Магадлал статистик\par}

{\large\bfseries Логистик регресс ашиглан орлогын түвшнийг илрүүлэх\par}

\vspace{2cm}

{\normalsize
Г.Жавхлан 22B1NUM3154\\
Б.Солонгоо 23B1NUM1034\\
Б.Балжинням 22B1NUM6983\\
Т.Баасандорж 22B1NUM0004\par}

\vfill

{\large Монгол Улсын Их Сургууль\par}
{\large Математик, Компьютерийн ухааны сургууль\par}

\vspace{1cm}

{\large \today\par}

\end{titlepage}

\newpage

\renewcommand{\contentsname}{Агуулга}
\tableofcontents

\newpage

\section{Оршил}\label{ux43eux440ux448ux438ux43b}

Энэ төслийн зорилго нь хувь хүний жилийн орлого 50,000 ам.доллараас дээш
эсэхийг таамаглах явдал юм. Бид АНУ-ын Хүн амын тооллогын Adult Income
өгөгдлийн санг ашиглан орлогын түвшинг урьдчилан таамаглах загвар
боловсруулна. Энэхүү өгөгдлийн сан нь нас, боловсрол, мэргэжил, гэр
бүлийн байдал зэрэг олон хувьсагчийг агуулдаг бөгөөд эдгээр нь хувь
хүний санхүүгийн байдалд нөлөөлдөг гол хүчин зүйлс юм.

Төслийн үндсэн зорилго нь зөвхөн таамаглал гаргах бус, өгөгдөл дэх
хамаарал, классын тэнцвэргүй байдал, оролцож буй хувьсагчдын нөлөөллийг
ойлгож, загварын үйл ажиллагааг үнэлэхэд оршино. Энд бид логистик
регрессийг ашиглан хоёртын ангиллын асуудлыг шийдвэрлэх ба загварын
үзүүлэлтүүд нь орлогыг зөв таамаглах боломжийг хэр сайн хангаж байгааг
илтгэнэ. Үүнээс гадна энэ төсөл нь өгөгдлийн шинжилгээ, ангиллын
загварчлал болон статистик үндэслэлтэй шийдвэр гаргалтын практик дадлага
олгоно.

\section{Өгөгдөл}\label{ux4e9ux433ux4e9ux433ux434ux4e9ux43b}

\subsection{Өгөгдлийн эх үүсвэр ба
зорилго}\label{ux4e9ux433ux4e9ux433ux434ux43bux438ux439ux43d-ux44dux445-ux4afux4afux441ux432ux44dux440-ux431ux430-ux437ux43eux440ux438ux43bux433ux43e}

Бид Kaggle платформын Income Dataset буюу орлогын мэдээллийг ашигласан.
Энэ өгөгдлийн багц дотор нас, боловсрол, мэргэжил, гэрлэлтийн байдал,
хүйс зэрэг нийгэм-эдийн засгийн шинж чанаруудыг илэрхийлэх хувьсагчид
бий. Бидний зорилтот хувьсагч бол \texttt{income\_\textgreater{}50K} (0
= \(\leq50K\), 1 = \(>50K\)). Өгөгдлийг цэвэрлэсний дараа үлдсэн
хувьсагчууд дээр тулгуурлан энэ хувьсагчийн утгыг зөв таамаглах нь
бидний үндсэн зорилго юм.

Түүврийн нийт хэмжээ нь ойролцоогоор 44,000 бөгөөд бид үүнийг сургах
болон үнэлгээ хийх 2 хэсэг болгож хуваана. Хуваалтын дараа 35,165
сургалт, 8,792 баталгаажуулалтын хэсгийг бүрдүүлнэ.

Гэхдээ энэ өгөгдөлтэй ажиллах томоохон бэрхшээл нь классуудын тэнцвэргүй
байдал юм. Ихэнх хүмүүс (\(\approx\) 76\%) \(\leq50K\) орлоготой. Харин
цөөнх хувь нь (\(\approx\) 24\%) \(>50K\) орлоготой.

Бид үргэлж \(\leq50K\) гэж таадаг гэнэн модел гаргасан ч accuracy нь
76\% болно гэсэн үг. Иймээс бид 2 классыг хоёуланг нь оновтойгоор авч
үздэг логистик регресс загвар гаргах ёстой болоод байна. Үүний тулд F1
оноо, Recall зэрэг үзүүлэлтүүдийг чухалчилна.

\subsection{Өгөгдлөө
цэвэрлэх}\label{ux4e9ux433ux4e9ux433ux434ux43bux4e9ux4e9-ux446ux44dux432ux44dux440ux43bux44dux445}

Өгөгдлийн хэлбэр:

\([\)
\texttt{age},\texttt{workclass},\texttt{fnlwgt},\texttt{education},\texttt{educational-num},\texttt{marital-status},\texttt{occupation},\texttt{relationship},\texttt{race},\texttt{gender},\texttt{capital-gain},\texttt{capital-loss},\texttt{hours-per-week},\texttt{native-country},\texttt{income\_\textgreater{}50K}
\(]\)

Бид анхны өгөгдөлөө давхардсан, ач холбогдол багатай буюу тайлбарлахад
хэцүү баганыг арилгаж хялбаршуулсан.

\textbf{Ашигласан хувьсагчид (9):}

\begin{itemize}
\item
  Тоон (5): \texttt{age}, \texttt{educational-num},
  \texttt{capital-gain}, \texttt{capital-loss}, \texttt{hours-per-week}
\item
  Чанарын (4): \texttt{education}, \texttt{marital-status},
  \texttt{occupation}, \texttt{gender}
\end{itemize}

\subsection{Өгөгдөл
хуваах}\label{ux4e9ux433ux4e9ux433ux434ux4e9ux43b-ux445ux443ux432ux430ux430ux445}

Бид өгөгдлийг сургалт/баталгаажуулалт гэсэн хоёр хэсэгт \textbf{80/20}
харьцаатайгаар, хоёр хэсэгт \texttt{income\_\textgreater{}50K} классын
харьцаа тэнцүү байхаар хувааж, \texttt{train\_split.csv},
\texttt{val\_split.csv} файлд хадгалсан. Анхны өгөгдлийн багц дотор
\texttt{income\_\textgreater{}50K}-н 76\% нь 0, 24\% нь 1 утгатай бол
хуваасны дараа энэ харьцаа эвдлээгүй гэсэн үг.

\subsection{Урьдчилсан
боловсруулалт}\label{ux443ux440ux44cux434ux447ux438ux43bux441ux430ux43d-ux431ux43eux43bux43eux432ux441ux440ux443ux443ux43bux430ux43bux442}

\textbf{Тоон хувьсагчид:}\\
StandardScaler нь тоон хувьсагч бүрийг дундаж утга нь 0, стандарт
хазайлт нь 1 болохоор нормальчилдаг. Бүх хувьсагчийг түүврийн дундаж руу
нь төвлөрүүлснээр градиент дээр суурилсан алгоритмууд илүү хурдан,
тогтвортой суралцахад тусална.

\[
X_{\text{scaled}} = \frac{X - \mu}{\sigma}
\]

\textbf{Чанарын хувьсагчид:}\\
OneHotEncoder нь нэг чанарын хувьсагчийг тус бүрийн чанаруудыг
илэрхийлэх хоёртын вектор лүү хөрвүүлж, тоон утгаар илэрхийлдэг нь машин
сургалтын алгоритмуудад зохимжтой болгоно. Ямар ч дараалал, зэрэглэл авч
үздэггүй.

Жишээлбэл, \texttt{education} гэх чанарын хувьсагчийг авч үзье.

\([E = \{\text{HS}, \text{Bachelors}, \text{Masters}, \text{Doctorate}\}]\)

One-hot кодчилол нь уг хувьсагчийг дараах байдлаар хувиргана:

\[
f(x) = \begin{cases} [1, 0, 0, 0] & \text{if } x = \text{HS} \\[1mm][0, 1, 0, 0] & \text{if } x = \text{Bachelors} \\[1mm][0, 0, 1, 0] & \text{if } x = \text{Masters} \\[1mm][0, 0, 0, 1] & \text{if } x = \text{Doctorate} \end{cases}
\]

Кодлогдсон онцлог (feature) бүр нь одоо Бернуллийн санамсаргүй хувьсагч
болно.

\textbf{Загварын гиперпараметр:}

\begin{itemize}
\item
  \texttt{learning\_rate} ойролцоогоор 0.1
\item
  \texttt{max\_iter} ойролцоогоор 800
\item
  \texttt{reg\_lambda} = 1e-4 (L2)
\item
  \texttt{lr\_decay} = 1e-4
\item
  \texttt{threshold} = 0.5 (шийдвэрийн хязгаар)
\end{itemize}

\section{Загварын
хэрэгжүүлэлт}\label{ux437ux430ux433ux432ux430ux440ux44bux43d-ux445ux44dux440ux44dux433ux436ux4afux4afux43bux44dux43bux442}

Бид энэ төсөлд логистик регрессийн загварыг гараар хэрэгжүүлсэн. Яагаад
гэвэл sklearn-ийн \texttt{LogisticRegression} нь олон зүйлийг автоматаар
хийдэг бөгөөд бид хэрхэн ажилладгийг нь ойлгохыг илүүд үзлээ. Мөн сурах
хурдны бууралт, class weighting зэрэг сонирхолтой зүйлсийг өөрсдөө
туршиж үзэхийг хүссэн.

\subsection{Логистик регрессийн
үндэс}\label{ux43bux43eux433ux438ux441ux442ux438ux43a-ux440ux435ux433ux440ux435ux441ux441ux438ux439ux43d-ux4afux43dux434ux44dux441}

Логистик регресс нь хоёртын ангилал хийх суурь загваруудын нэг юм.
Шугаман регресс нь тасралтгүй утгуудыг таамагладаг бол логистик регресс
нь аливаа инстанц нь тодорхой классын байх магадлалыг тооцоолдог.

Оролтын хувьсагч \(\mathbf{x}\) -н хувьд \[
P(y = 1 \mid \mathbf{x})
\]

буюу гаралт \(y\) нь \(1\)-тэй тэнцүү байх магадлалыг олох зорилготой.

Эхлээд бид оролтуудын шугаман тэгшитгэлийг бодно:

\[
z_i = \mathbf{w}^\top \mathbf{x}_i + b
\]

Үүнд:

\begin{itemize}
\tightlist
\item
  \(\mathbf{w}\) = жингийн вектор (сурах параметрүүд)
\item
  \(b\) = хазайлтын утга
\item
  \(\mathbf{x}_i\) = түүврийн онцлогийн вектор \(i\)
\item
  \(z_i\) = logit'' буюу log odds
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ issparse(X\_array):}
\NormalTok{    z }\OperatorTok{=}\NormalTok{ X\_array.dot(}\VariableTok{self}\NormalTok{.weights) }\OperatorTok{+} \VariableTok{self}\NormalTok{.bias}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    z }\OperatorTok{=}\NormalTok{ np.dot(X\_array, }\VariableTok{self}\NormalTok{.weights) }\OperatorTok{+} \VariableTok{self}\NormalTok{.bias}
\end{Highlighting}
\end{Shaded}

\subsection{Сигмойд
функц}\label{ux441ux438ux433ux43cux43eux439ux434-ux444ux443ux43dux43aux446}

Сигмойд функц нь дээрх шугаман нийлбэр \(z\) -ийг магадлал болгоно.

\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ sigmoid(}\VariableTok{self}\NormalTok{, z):}
    \ControlFlowTok{return} \DecValTok{1} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{np.clip(z, }\OperatorTok{{-}}\DecValTok{500}\NormalTok{, }\DecValTok{500}\NormalTok{)))  }\CommentTok{\# overflow{-}оос сэргийлэх}
\end{Highlighting}
\end{Shaded}

Эндээс модел нэг түүврийн хувьд таамаглах магадлал нь дараах томъёгоор
илэрхийлэгдэнэ:

\[
\hat{p}_i = P(y_i = 1 \mid \mathbf{x}_i) = \sigma(z_i) = \sigma(\mathbf{w}^T \mathbf{x}_i + b)
\]

\subsection{Алдааны
функц}\label{ux430ux43bux434ux430ux430ux43dux44b-ux444ux443ux43dux43aux446}

Одоо бид загварыг яаж сургахын тулд алдааны функцийг тодорхойлох
хэрэгтэй. Логистик регресст binary cross-entropy хэмээх ойлголтыг
ашигладаг.

Нэг таамаглалын хувьд алдаа нь:

\[
\ell = -\left[y \log(\hat{y}) + (1-y)\log(1-\hat{y})\right]
\]

Үүнд:

\begin{itemize}
\tightlist
\item
  \(y\) = жинхэнэ утга (0 or 1)
\item
  \(\hat{y}\) = таамагласан утга
\end{itemize}

Cross-entropy нь загварыг итгэлтэйгээр буруу таамаглал гаргахыг илүү
шийтгэдэг. Өөрөөр хэлбэл 1 эсвэл 0-тэй маш ойрхон магадлал (0.99, 0.01
г.м.) гаргаад энэ нь буруу болж таарвал алдаа нь өндөр гарч ирнэ.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Таамаглал \(\hat{y}\) & Алдаа \(-\log(\hat{y})\) & Шийтгэлийн түвшин \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0.99 (итгэлтэй, зөв) & 0.01 & Маш бага \\
0.50 (итгэл багатай) & 0.69 & Дунд зэргийн \\
0.10 (итгэлтэй, буруу) & 2.30 & Том \\
0.01 (маш итгэлтэй, буруу) & 4.61 & Маш том \\
\end{longtable}

\[
L_{\text{CE}} = -\frac{1}{m}\sum_{i=1}^{m} 
\left[
y_i \log(\hat{y}_i) + (1 - y_i)\log(1 - \hat{y}_i)
\right].
\]

\subsection{L2 тогтворжуулалт
(regularization)}\label{l2-ux442ux43eux433ux442ux432ux43eux440ux436ux443ux443ux43bux430ux43bux442-regularization}

Хэт том утгатай жингээс үүдэлтэй overfitting-ээс сэргийлнэ

\[
\frac{\lambda}{2m}\|\mathbf{w}\|^2
\]

Үүнд:

\begin{itemize}
\item
  \(\lambda\) = тогтворжуулалтын хэмжээ (гиперпараметр)
\item
  \(m\) = түүврийн хэмжээ
\item
  \(\|\mathbf{w}\|^2 = w_1^2 + w_2^2 + \cdots + w_n^2\)
\end{itemize}

Нийт алдаа:

\[
L = -\frac{1}{m}\sum_{i=1}^{m}\left[y_i\log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)\right] + \frac{\lambda}{2m}\|\mathbf{w}\|^2
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ compute\_loss(}\VariableTok{self}\NormalTok{, y\_true, y\_pred, sample\_weights}\OperatorTok{=}\VariableTok{None}\NormalTok{):}

\NormalTok{    m }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(y\_true)}
    
\NormalTok{    epsilon }\OperatorTok{=} \FloatTok{1e{-}15}
\NormalTok{    y\_pred }\OperatorTok{=}\NormalTok{ np.clip(y\_pred, epsilon, }\DecValTok{1} \OperatorTok{{-}}\NormalTok{ epsilon)}
    
\NormalTok{    sample\_losses }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{(y\_true }\OperatorTok{*}\NormalTok{ np.log(y\_pred) }\OperatorTok{+} 
\NormalTok{                      (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ y\_true) }\OperatorTok{*}\NormalTok{ np.log(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ y\_pred))}
    
    \ControlFlowTok{if}\NormalTok{ sample\_weights }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{        sample\_losses }\OperatorTok{=}\NormalTok{ sample\_losses }\OperatorTok{*}\NormalTok{ sample\_weights}
    
\NormalTok{    cross\_entropy }\OperatorTok{=}\NormalTok{ np.mean(sample\_losses)}
    
\NormalTok{    l2\_penalty }\OperatorTok{=}\NormalTok{ (}\VariableTok{self}\NormalTok{.reg\_lambda }\OperatorTok{/}\NormalTok{ (}\DecValTok{2} \OperatorTok{*}\NormalTok{ m)) }\OperatorTok{*}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{(}\VariableTok{self}\NormalTok{.weights }\OperatorTok{**} \DecValTok{2}\NormalTok{)}
    
    \ControlFlowTok{return}\NormalTok{ cross\_entropy }\OperatorTok{+}\NormalTok{ l2\_penalty}
\end{Highlighting}
\end{Shaded}

\subsection{Градиент бууруулалт (Gradient
descent)}\label{ux433ux440ux430ux434ux438ux435ux43dux442-ux431ux443ux443ux440ux443ux443ux43bux430ux43bux442-gradient-descent}

Одоо манай алдагдлын функц бий. Гэхдээ нийт алдааг хэрхэн багасгахын
тулд градиент бууруулалт гэж нэрлэгддэг аргыг ашиглана. Энэ тохиолдолд
градиент гэдэг нь жингүүдийн аль чиглэлд өөрчлөгдөх үед алдаа нь хамгийн
хурдтай өсөж буурахыг илэрхийлдэг вектор.. Градиент бууруулалтын үндсэн
санаа нь уг градиентыг тооцоолоход оршино.

Жин шинэчлэлийн дүрэм:

\[
\begin{aligned}
w &\leftarrow w - \alpha \cdot \nabla_w J \\
b &\leftarrow b - \alpha \cdot \nabla_b J
\end{aligned}
\]

Энд \(\alpha\) бол \textbf{сурах хурд} --- бид хэр хурдан алхах вэ
гэдгийг тодорхойлдог. Градиентууд нь:

\[
\begin{aligned}
\nabla_w J &= \frac{1}{m}X^\top(\hat{y} - y) + \frac{\lambda}{m}w \\
\nabla_b J &= \frac{1}{m}\sum_{i=1}^{m}(\hat{y}^{(i)} - y^{(i)})
\end{aligned}
\]

Кодонд:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ \_compute\_gradients(}\VariableTok{self}\NormalTok{, X, y, y\_pred):}
\NormalTok{    m }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(y)}
\NormalTok{    error }\OperatorTok{=}\NormalTok{ y\_pred }\OperatorTok{{-}}\NormalTok{ y}
    
    \CommentTok{\# Жингийн градиент + L2}
\NormalTok{    dw }\OperatorTok{=}\NormalTok{ (}\DecValTok{1}\OperatorTok{/}\NormalTok{m) }\OperatorTok{*}\NormalTok{ X.T.dot(error)}
    \ControlFlowTok{if} \VariableTok{self}\NormalTok{.reg\_lambda }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{        dw }\OperatorTok{+=}\NormalTok{ (}\VariableTok{self}\NormalTok{.reg\_lambda }\OperatorTok{/}\NormalTok{ m) }\OperatorTok{*} \VariableTok{self}\NormalTok{.weights}
    
    \CommentTok{\# Bias{-}ийн градиент}
\NormalTok{    db }\OperatorTok{=}\NormalTok{ (}\DecValTok{1}\OperatorTok{/}\NormalTok{m) }\OperatorTok{*}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{(error)}
    
    \ControlFlowTok{return}\NormalTok{ dw, db}
\end{Highlighting}
\end{Shaded}

\subsection{Сурах хурдны бууралт: Оновчтой
конвергенц}\label{ux441ux443ux440ux430ux445-ux445ux443ux440ux434ux43dux44b-ux431ux443ux443ux440ux430ux43bux442-ux43eux43dux43eux432ux447ux442ux43eux439-ux43aux43eux43dux432ux435ux440ux433ux435ux43dux446}

Нэг асуудал: хэрэв сурах хурд хэт өндөр бол, алдагдлын функцийн
минимумыг алдаж, ``bounce around'' хийж магадгүй. Хэт бага бол, маш
удаан сургана. Шийдэл нь юу вэ? \textbf{Сурах хурдны бууралт} --- эхлээд
том алхамуудаар эхлээд, цаг хугацааны явцад багасгана:

\[
\alpha_t = \frac{\alpha_0}{1 + \text{decay} \cdot t}
\]

Энэ нь загварт эхэндээ хурдан суралцах, дараа нь минимумын ойролцоо
нарийвчлалтай алхах боломж олгоно. Кодонд:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ iteration }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\VariableTok{self}\NormalTok{.max\_iter):}
    \CommentTok{\# Одоогийн сурах хурдыг тооцоолох}
\NormalTok{    current\_lr }\OperatorTok{=} \VariableTok{self}\NormalTok{.initial\_lr }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+} \VariableTok{self}\NormalTok{.lr\_decay }\OperatorTok{*}\NormalTok{ iteration)}
    
    \CommentTok{\# Жингүүдийг шинэчлэх}
    \VariableTok{self}\NormalTok{.weights }\OperatorTok{{-}=}\NormalTok{ current\_lr }\OperatorTok{*}\NormalTok{ dw}
    \VariableTok{self}\NormalTok{.bias }\OperatorTok{{-}=}\NormalTok{ current\_lr }\OperatorTok{*}\NormalTok{ db}
\end{Highlighting}
\end{Shaded}

\subsection{Классын жинлэлт: Тэнцвэргүй өгөгдөлтэй
ажиллах}\label{ux43aux43bux430ux441ux441ux44bux43d-ux436ux438ux43dux43bux44dux43bux442-ux442ux44dux43dux446ux432ux44dux440ux433ux4afux439-ux4e9ux433ux4e9ux433ux434ux4e9ux43bux442ux44dux439-ux430ux436ux438ux43bux43bux430ux445}

Манай өгөгдөлд 76\% нь \(\leq50K\), 24\% нь \(>50K\) байна. Хэрэв бид юу
ч хийхгүй бол, загвар зүгээр л ``бүх зүйл \(\leq50K\)'' гэж таамаглаж,
76\% нарийвчлалд хүрч магадгүй --- гэхдээ энэ нь ямар ч хэрэггүй юм!

Шийдэл нь \textbf{классын жинлэлт} юм. Бид цөөнх классын
(\textgreater50K) алдааг илүү ``чухал'' болгоно:

\[
w_{\text{class}} = \frac{m}{2 \cdot m_{\text{class}}}
\]

Кодонд:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \VariableTok{self}\NormalTok{.class\_weight }\OperatorTok{==} \StringTok{\textquotesingle{}balanced\textquotesingle{}}\NormalTok{:}
\NormalTok{    classes }\OperatorTok{=}\NormalTok{ np.unique(y)}
\NormalTok{    weights }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(y) }\OperatorTok{/}\NormalTok{ (}\BuiltInTok{len}\NormalTok{(classes) }\OperatorTok{*}\NormalTok{ np.bincount(y.astype(}\BuiltInTok{int}\NormalTok{)))}
\NormalTok{    sample\_weights }\OperatorTok{=}\NormalTok{ weights[y.astype(}\BuiltInTok{int}\NormalTok{)]}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    sample\_weights }\OperatorTok{=}\NormalTok{ np.ones(}\BuiltInTok{len}\NormalTok{(y))}

\CommentTok{\# Алдагдлыг тооцоолохдоо sample\_weights ашиглах}
\NormalTok{loss }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{np.mean(sample\_weights }\OperatorTok{*}\NormalTok{ (y }\OperatorTok{*}\NormalTok{ np.log(y\_pred\_clipped) }\OperatorTok{+} 
\NormalTok{                                   (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ y) }\OperatorTok{*}\NormalTok{ np.log(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ y\_pred\_clipped)))}
\end{Highlighting}
\end{Shaded}

\subsection{Пайплайн}\label{ux43fux430ux439ux43fux43bux430ux439ux43d}

Sklearn-ийн \texttt{Pipeline} нь бүх зүйлийг зохион байгуулахад туслана.
Бид preprocess (StandardScaler + OneHotEncoder) болон манай custom
LogisticRegression-г нэг л обьект болгон нэгтгэж чаддаг:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
\ImportTok{from}\NormalTok{ sklearn.compose }\ImportTok{import}\NormalTok{ ColumnTransformer}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler, OneHotEncoder}

\CommentTok{\# Тоон ба категори баганыг тусгаарлах}
\NormalTok{num\_features }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}age\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}educational{-}num\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}capital{-}gain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}capital{-}loss\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}hours{-}per{-}week\textquotesingle{}}\NormalTok{]}
\NormalTok{cat\_features }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}education\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}marital{-}status\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}occupation\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}gender\textquotesingle{}}\NormalTok{]}

\CommentTok{\# Preprocessing pipeline}
\NormalTok{preprocessor }\OperatorTok{=}\NormalTok{ ColumnTransformer([}
\NormalTok{    (}\StringTok{\textquotesingle{}num\textquotesingle{}}\NormalTok{, StandardScaler(), num\_features),}
\NormalTok{    (}\StringTok{\textquotesingle{}cat\textquotesingle{}}\NormalTok{, Pipeline([}
\NormalTok{        (}\StringTok{\textquotesingle{}encoder\textquotesingle{}}\NormalTok{, OneHotEncoder(drop}\OperatorTok{=}\StringTok{\textquotesingle{}first\textquotesingle{}}\NormalTok{, sparse\_output}\OperatorTok{=}\VariableTok{False}\NormalTok{, handle\_unknown}\OperatorTok{=}\StringTok{\textquotesingle{}ignore\textquotesingle{}}\NormalTok{))}
\NormalTok{    ]), cat\_features)}
\NormalTok{])}

\CommentTok{\# Бүтэн pipeline}
\NormalTok{model }\OperatorTok{=}\NormalTok{ Pipeline([}
\NormalTok{    (}\StringTok{\textquotesingle{}preprocess\textquotesingle{}}\NormalTok{, preprocessor),}
\NormalTok{    (}\StringTok{\textquotesingle{}logreg\textquotesingle{}}\NormalTok{, LogisticRegression(}
\NormalTok{        learning\_rate}\OperatorTok{=}\FloatTok{0.1}\NormalTok{, max\_iter}\OperatorTok{=}\DecValTok{800}\NormalTok{, reg\_lambda}\OperatorTok{=}\FloatTok{1e{-}4}\NormalTok{,}
\NormalTok{        lr\_decay}\OperatorTok{=}\FloatTok{1e{-}4}\NormalTok{, class\_weight}\OperatorTok{=}\StringTok{\textquotesingle{}balanced\textquotesingle{}}\NormalTok{, threshold}\OperatorTok{=}\FloatTok{0.5}
\NormalTok{    ))}
\NormalTok{])}

\NormalTok{model.fit(X\_train, y\_train)}
\end{Highlighting}
\end{Shaded}

\section{Үр дүн}\label{ux4afux440-ux434ux4afux43d}

\subsection{Ерөнхий
гүйцэтгэл:}\label{ux435ux440ux4e9ux43dux445ux438ux439-ux433ux4afux439ux446ux44dux442ux433ux44dux43b}

Эдгээр тоонууд юу гэсэн үг вэ? Бидний загвар ерөнхийдөө сайн ажилладаг
боловч цөөнх классыг (\textgreater50K) таних нь илүү хэцүү байна. Энэ нь
тэнцвэргүй өгөгдлийн ердийн асуудал юм.

\subsection{Confusion
матриц}\label{confusion-ux43cux430ux442ux440ux438ux446}

Confusion матриц нь манай алдаануудын төрлийг харуулна:

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images/conmatrix.png}}

}

\caption{Confusion матриц}

\end{figure}%

Яагаад вэ? Өгөгдөл тэнцвэргүй байгаа учраас, энэ загвар байнга олонх
классыг (\(\leq50K\)) харахаар сургагдсан. Энэ нь цөөнх классыг таних нь
хэцүү болгодог.

\subsection{Класс тус бүр дээрх
гүйцэтгэл}\label{ux43aux43bux430ux441ux441-ux442ux443ux441-ux431ux4afux440-ux434ux44dux44dux440ux445-ux433ux4afux439ux446ux44dux442ux433ux44dux43b}

Класс тус бүрээр нарийвчлан харвал:

\textbf{\(\leq50K\) анги (олонх):} - Precision: 0.89 - Recall: 0.91\\
- F1: 0.90

Загвар энэ классыг амархан таньдаг.

\textbf{\(>50K\) анги (цөөнх):} - Precision: 0.66 - Recall: 0.59 - F1:
0.62

Илүү муу. Энэ нь тэнцвэргүй өгөгдлийн шууд үр дагавар --- цөөн дээжтэй
ангиудыг суралцах нь хэцүү.

\subsection{Онцлогийн ач
холбогдол}\label{ux43eux43dux446ux43bux43eux433ux438ux439ux43d-ux430ux447-ux445ux43eux43bux431ux43eux433ux434ux43eux43b}

Жингүүдийг харахад, юу хамгийн чухал болохыг харж болно. Эхний 5 эерэг
ба сөрөг онцлогууд:

\textbf{Эерэг нөлөө (\textgreater50K рүү ойртуулах):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{\texttt{educational-num} (+0.89):} Боловсрол өндөр байх тусам
  орлого өндөр байх магадлал ихтэй.
\item
  \textbf{\texttt{capital-gain} (+0.76):} Хэрэв та хөрөнгө оруулалтаас
  орлого олж байвал орлого өндөр байх магадлал дээшилнэ.
\item
  \textbf{\texttt{marital-status\_Married-civ-spouse} (+0.46):} Гэрлэсэн
  хүмүүс илүү тогтвортой орлоготой байх хандлагатай.
\item
  \textbf{\texttt{occupation\_Exec-managerial} (+0.52):} Удирдах албан
  тушаал = илүү өндөр цалин.
\item
  \textbf{\texttt{hours-per-week} (+0.28):} Илүү их ажилласан = илүү их
  мөнгө.
\end{enumerate}

\textbf{Сөрөг нөлөө (\(\leq50K\) рүү ойртуулах):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{\texttt{occupation\_Other-service} (-0.67):} Үйлчилгээний ажил
  ихэвчлэн бага цалинтай.
\item
  \textbf{\texttt{marital-status\_Never-married} (-0.48):} Ганц бие байх
  нь бага орлоготой холбоотой (гэхдээ бодит байдалд бусад хүчин зүйлээс
  шалтгаалж магадгүй).
\item
  \textbf{\texttt{capital-loss} (-0.41):} Хөрөнгийн алдагдал санхүүгийн
  асуудлын шинж тэмдэг.
\item
  \textbf{\texttt{education\_HS-grad} (-0.32):} Бүрнэ дунд боловсрол
  дангаараа өндөр орлого хангахад хүрэлцэхгүй.
\end{enumerate}

\subsection{Магадлалын
тархалт}\label{ux43cux430ux433ux430ux434ux43bux430ux43bux44bux43d-ux442ux430ux440ux445ux430ux43bux442}

Сигмоид функц шугаман нийлбэр буюу linear combination-ийг
(\(z = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b\)) магадлал руу
хөрвүүлдэг.

\textbf{\(\leq50K\) хүмүүсийн хувьд:} - Дундаж магадлал (\textgreater50K
байх): \textbf{0.18} - Ихэнх нь 0-0.3 хооронд

Загвар эдгээр хүмүүсийг 100\% эерэг биш гэж бодож байна, гэхдээ ихэвчлэн
магадлалыг бага байлгадаг.

\textbf{\(>50K\) хүмүүсийн хувьд:} - Дундаж магадлал: \textbf{0.57} -
Илүү өргөн тархалттай (0.2-0.9)

Зарим \textgreater50K орлоготой хүмүүс өндөр магадлалтай (0.9+) гарч
байгаа ч, зарим нь харьцангуй бага магадлалтай (0.2--0.4) байна. Энэ
магадлалын давхцал нь загвар төгс ажиллахаас өөр аргагүйг харуулж байна.
Зарим өгөгдөл дээр тодорхой ангилалт хийх хэцүү.

\subsection{PR Trade-off}\label{pr-trade-off}

Яагаад бид 100\% precision ба 100\% recall-д зэрэг хүрч чадахгүй гэж?

Математик талаас боломжгүй, учир нь ангиуд заримдаа давхцдаг. Манай
магадлалын тархалтын график үүнийг тодорхой харуулна. Зарим өндөр
орлоготой хүмүүсийг загвар бага магадлалтай гэж үзэж, зарим \(\leq50K\)
хүмүүс өндөр магадлалтай гэж үнэлдэг. Иймээс бид аль ч загвараар 100\%
зөв ангилах боломжгүй.

Загварын ерөнхий гүйцэтгэлийг ROC AUC=0.891 үзүүлж байна. Энэ нь
санамсаргүй таамаглалаас (0.5) илүү сайн бөгөөд ангилалд дунджаар
үнэлгээ сайн байгааг харуулна. Төгс үзүүлэлт биш (1.0), гэхдээ оюутны
төсөлд анхны оролдлого болгон маш сайн гүйцэтгэл юм.

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images/PRC.png}}

}

\caption{Precision-Recall ба ROC муруйнууд}

\end{figure}%

Зүүн талын Precision--Recall муруй нь бидний хамгийн том шийдвэрийн
тэнцвэрийг илтгэнэ. Recall-ийг өсгөх үед илүү олон өндөр орлоготой
хүмүүсийг илрүүлэх боломжтой ч, босго оноо доошлохын хэрээр Precision
буурч, буруу эерэг таамаглал нэмэгддэг. Харин Precision-ийг сайжруулахын
тулд илүү хатуу босго тавибал загвар зөв таамаглалд илүү итгэлтэй болох
авч, олон жинхэнэ өндөр орлоготой хүмүүсийг орхигдуулах эрсдэлтэй. Энэ
муруй нь хоёр классын үл тэнцвэртэй өгөгдлийн үед бодит гүйцэтгэлийг
илүү үнэн зөв харуулдаг тул стратегийн хувьд түлхүүр үзүүлэлт болдог.

Баруун талын ROC муруй харьцангуй ерөнхий дүр зургийг өгч, манай
загварын ялгах чадвар AUC = 0.891 гэдгийг харуулж байна. Энэ нь
санамсаргүй таамаглалаас эрс илүү гүйцэтгэлтэй боловч ROC муруйн нь үл
тэнцвэртэй өгөгдөлд хэт өгөөмөр ханддаг гэдгийг мартаж болохгүй. Иймээс
өндөр AUC үзүүлэлт нь өөрөө хангалттай биш: практикт бид босго оноог
бодитоор тохируулж, Precision ба Recall-ийн хооронд төслийн зорилгод
нийцсэн зөв тэнцвэрийг олох шаардлагатай хэвээр байна.

\subsection{Онцлогийн
жин}\label{ux43eux43dux446ux43bux43eux433ux438ux439ux43d-ux436ux438ux43d}

Жингүүд нь онцлогийн чухал байдлыг харуулна. Эерэг жин = өндөр орлого
руу түлхэх, сөрөг жин = бага орлого руу түлхэх:

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images/features.png}}

}

\caption{Хамгийн чухал 15 онцлогийн жин}

\end{figure}%

Хамгийн өндөр нөлөөтэй хүчин зүйлс:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{educational-num (+0.89):} Боловсролын түвшин. Энэ нь хамгийн
  хүчтэй эерэг нөлөөтэй хүчин зүйл болж байна. Боловсрол өндөр байх
  тусам орлого өндөр байх магадлал эрс нэмэгдэнэ.
\item
  \textbf{capital-gain (+0.76):} Хөрөнгө оруулалтын ашиг. Санхүүгийн
  нэмэлт эх үүсвэртэй байх нь өндөр орлогын тод шинж тэмдэг юм.
\item
  \textbf{occupation\_Other-service (-0.67):} Үйлчилгээний салбарын
  ажил. Энэ нь орлогод сөргөөр нөлөөлж байна, өөрөөр хэлбэл энэ салбарт
  ажиллагсад \(\leq50K\) классд орох магадлал өндөр.
\item
  \textbf{marital-status\_Never-married (-0.48):} Гэрлэж байгаагүй. Ганц
  бие хүмүүс гэр бүлтэй хүмүүстэй харьцуулахад орлого багатай байх
  хандлага ажиглагдсан.
\item
  \textbf{marital-status\_Married-civ-spouse (+0.46):} Гэрлэсэн байдал.
  Эсрэгээрээ, гэр бүлийн тогтвортой байдал нь өндөр орлоготой эерэг
  хамааралтай байна.
\end{enumerate}

Эдгээр үр дүн нь нийгэм, эдийн засгийн бодит байдалтай бүрэн нийцэж
байна. Загвар маань зүгээр нэг тоо таах биш, бодит амьдралын зүй тогтлыг
олж харсан гэж дүгнэж болно.

\subsection{Сигмоид функц ба магадлалын
тархалт}\label{ux441ux438ux433ux43cux43eux438ux434-ux444ux443ux43dux43aux446-ux431ux430-ux43cux430ux433ux430ux434ux43bux430ux43bux44bux43d-ux442ux430ux440ux445ux430ux43bux442}

Сигмоид функц нь загварын гаргасан тоон үнэлгээг (score) магадлал руу
хөрвүүлдэг. Зүүн талд математик функц, баруун талд бидний загварын бодит
таамаглалууд хэрхэн тархсаныг харуулж байна:

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{images/sigmoid.png}}

}

\caption{Сигмоид функц ба магадлалын тархалт}

\end{figure}%

\textbf{Гол ойлголт:} Зүүн талын график нь онолын хэсэг --- \(z=0\) үед
магадлал яг 0.5 байна. Харин баруун талын гистограм нь бодит байдлыг
харуулна:

\begin{itemize}
\tightlist
\item
  \textbf{Улаан хэсэг (\(\leq50K\)):} Ихэнх нь 0-0.3 магадлалтай байна.
  Загвар энэ хүмүүсийг бага орлоготой гэдэгтээ нэлээд итгэлтэй байна.
\item
  \textbf{Ногоон хэсэг (\textgreater50K):} Тархалт нь 0.2-оос 0.9 хүртэл
  маш өргөн байна. Энд давхцал их байгааг анзаараарай.
\item
  Энэ давхцал нь яагаад бид 100\% нарийвчлалтай байж чадахгүйг
  тайлбарладаг. Зарим өндөр орлоготой хүмүүс бага орлоготой хүмүүстэй
  ижил шинж чанартай (эсвэл эсрэгээрээ) байгаа тул загвар тэднийг
  ялгахад хүндрэлтэй байна.
\end{itemize}

\subsection{Дүгнэлт}\label{ux434ux4afux433ux43dux44dux43bux442}

Энэхүү төсөл нь логистик регрессийг практикт хэрэгжүүлэх явцдаа зөвхөн
алгоритмын ажиллагаа төдийгүй өгөгдлийн чанар, статистик ойлголтууд
загварын гүйцэтгэлд ямар их нөлөөтэйг бодитоор мэдрэх боломж олголоо.
Загвар тогтвортой суралцаж, хэт тохируулалт ажиглагдаагүй нь зөв
регуляризацийн сонголт болон градиент бууруулалтын тохиргоо оновчтой
байсны илрэл юм. Гэсэн хэдий ч гүйцэтгэл, ялангуяа accuracy нь 80\%
давахгүй байгаа нь өгөгдлийн бүтэц, классын тэнцвэргүй байдал зэрэгтэй
холбоотой.

Ирээдүйд Random Forest, Gradient Boosting зэрэг илүү нарийн төвөгтэй
загваруудыг ашиглавал \textgreater50K орлоготой хүмүүсийг илүү
найдвартай таамаглах боломжтой. Гол сургамж нь зөвхөн Accuracy-аас гадна
Precision, Recall, ROC/AUC зэрэг үзүүлэлтүүдийг ойлгон, загварын
хязгаарлалт, өгөгдлийн чанарыг хамтад нь үнэлэх хэрэгтэй гэдгийг харуулж
байна.




\end{document}
